{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO\n",
    "# Finish commenting functions\n",
    "# Add titles and labels to graphs\n",
    "# Add Min/Max scaling\n",
    "# scrape news/headlines, build regressions off of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from matplotlib.pylab import rcParams\n",
    "import numpy as np\n",
    "from statsmodels.graphics.tsaplots import plot_pacf\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "from statsmodels.tsa.arima_model import ARMA\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from pmdarima import auto_arima\n",
    "\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "import statsmodels.api as sm\n",
    "from matplotlib.pylab import rcParams\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tsa.stattools import acf\n",
    "from statsmodels.tsa.stattools import pacf\n",
    "\n",
    "from fbprophet import Prophet\n",
    "from fbprophet.diagnostics import performance_metrics\n",
    "from fbprophet.diagnostics import cross_validation\n",
    "from fbprophet.plot import plot_cross_validation_metric\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre Process Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepares the data for modeling\n",
    "def preprocess(init_data, exog=True, facebook=False, logged=False):\n",
    "    \n",
    "    # Log transform data if wanted\n",
    "    if logged:\n",
    "        data = init_data.copy()\n",
    "        for i in range(1,len(init_data.columns)):\n",
    "            col = init_data.columns[i]\n",
    "            data[col] = np.log(init_data[col])\n",
    "    else:\n",
    "        data = init_data.copy()\n",
    "    \n",
    "    ## Drops unwanted columns and returns dataset\n",
    "    \n",
    "    # Preprocess specific to facebook prophet\n",
    "    if facebook:\n",
    "        fb = data.copy()\n",
    "        fb['Date'] = pd.DatetimeIndex(fb['Date'])\n",
    "        fb = fb.drop(['Open','High','Low','Close','Volume'],axis=1)\n",
    "        fb = fb.rename(columns={'Date': 'ds','Adj Close':'y'})\n",
    "        return fb\n",
    "    \n",
    "    # If using volume, splits data into 2 separate series for modeling\n",
    "    elif exog:\n",
    "        X = data.drop(['Open','High','Low','Close'],axis=1)\n",
    "        X['Date'] = pd.to_datetime(X['Date'])\n",
    "        X = X.set_index('Date')\n",
    "#         start = X['Date'][0]\n",
    "#         end = X['Date'][len(X)-1]\n",
    "        return X['Adj Close'],X['Volume']\n",
    "    else:\n",
    "        X = data.drop(['Open','High','Low','Close','Volume'],axis=1)\n",
    "        X['Date'] = pd.to_datetime(X['Date'])\n",
    "        X = X.set_index('Date')\n",
    "        return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roi_calc(start,end):\n",
    "    return round((end-start)/start*100,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns amount of periods to difference data, using adfuller method\n",
    "def return_d(data,alpha=0.05, plotting = False, output = False):\n",
    "    # Uses differencing and adfuller method to find d value for ARIMA models\n",
    "    diff = data.copy()\n",
    "    d = 0\n",
    "    \n",
    "    # Iterates through a default range of 30 periods and finds the first period where differenced data is stationary\n",
    "    for j in range(30):\n",
    "        dtest = adfuller(diff)\n",
    "        if dtest[1] < alpha:\n",
    "            \n",
    "            # Plots differenced data\n",
    "            if plotting:\n",
    "                diff.plot()\n",
    "                plt.xlabel('Date')\n",
    "                plt.ylabel('Price')\n",
    "                plt.title(('Differencing with Periods ='+str(j)))\n",
    "            \n",
    "            # Prints stat values\n",
    "            if output:\n",
    "                dfoutput = pd.Series(dtest[0:4], index=['Test Statistic', 'p-value', '#Lags Used', 'Number of Observations Used'])\n",
    "                for key,value in dtest[4].items():\n",
    "                    dfoutput['Critical Value (%s)'%key] = value\n",
    "                print(dfoutput)\n",
    "            d = j\n",
    "            return d\n",
    "        else:\n",
    "            # Differences the data one additional period and checks adfuller method\n",
    "            diff = diff.diff(periods=j+1).dropna()\n",
    "    return d              \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns suggestion for moving average's p\n",
    "def return_p(data,alpha=0.05, plotting = False):\n",
    "    # Determine if data needs differencing first\n",
    "    d = return_d(data,alpha)\n",
    "    new_data = data.copy()\n",
    "    if d > 0:\n",
    "        new_data = data.diff(periods=d).dropna()\n",
    "    \n",
    "    # Uses pacf to find p value for ARIMA models\n",
    "    data_pacf = pacf(new_data)\n",
    "    p = 0\n",
    "\n",
    "    # Plots PACF\n",
    "    if plotting:\n",
    "        plot_pacf(new_data,alpha=alpha)\n",
    "        plt.xlabel('Lags')\n",
    "        plt.ylabel('PACF')\n",
    "    \n",
    "    # Returns first p value less than alpha\n",
    "    for k in range(len(data_pacf)):\n",
    "        if (abs(data_pacf[k])) < alpha:\n",
    "            p = k-1\n",
    "            return p\n",
    "        \n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns suggestion for auto regressive's q\n",
    "def return_q(data, alpha=0.05, plotting = False):\n",
    "    # Determine if data needs differencing first\n",
    "    d = return_d(data,alpha)\n",
    "    new_data = data.copy()\n",
    "    if d > 0:\n",
    "        new_data = data.diff(periods=d).dropna()\n",
    "        \n",
    "    # uses acf to find q value for ARIMA models\n",
    "    data_acf = acf(new_data)\n",
    "    q = 0\n",
    "    \n",
    "    # Plots ACF\n",
    "    if plotting:\n",
    "        plot_acf(new_data,alpha=alpha)\n",
    "        plt.xlabel('Lags')\n",
    "        plt.ylabel('ACF')\n",
    "    \n",
    "    # Returns first q value less than alpha\n",
    "    for i in range(len(data_acf)):\n",
    "        if (abs(data_acf[i])) < alpha:\n",
    "            q = i-1\n",
    "            return q\n",
    "    return q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots seasonal trends if any\n",
    "def seasonal(data):\n",
    "    decomposition = seasonal_decompose(data)\n",
    "\n",
    "    # Gather the trend, seasonality, and residuals \n",
    "    trend = decomposition.trend\n",
    "    seasonal = decomposition.seasonal\n",
    "    residual = decomposition.resid\n",
    "\n",
    "    # Plot gathered statistics\n",
    "    plt.figure(figsize=(12,8))\n",
    "    plt.subplot(411)\n",
    "    plt.plot(data, label='Original', color='blue')\n",
    "    plt.legend(loc='best')\n",
    "    plt.subplot(412)\n",
    "    plt.plot(trend, label='Trend', color='blue')\n",
    "    plt.legend(loc='best')\n",
    "    plt.subplot(413)\n",
    "    plt.plot(seasonal,label='Seasonality', color='blue')\n",
    "    plt.legend(loc='best')\n",
    "    plt.subplot(414)\n",
    "    plt.plot(residual, label='Residuals', color='blue')\n",
    "    plt.legend(loc='best')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to return order values for use in base model\n",
    "def model_params(data, exog=True, logged=False):\n",
    "    if exog:\n",
    "        new_data, ex = preprocess(init_data=data,exog=exog,logged=logged)\n",
    "    else:\n",
    "        new_data = preprocess(init_data=data,exog=exog,logged=logged)\n",
    "    p = return_p(new_data)\n",
    "    q = return_q(new_data)\n",
    "    d = return_d(new_data)\n",
    "    return p,d,q\n",
    "    print(\"Returns: p, d, q\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Test Split Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splits train/test data specific to time series \n",
    "def train_test(data,exog=True, percent =.75,facebook=False, logged=False, full=False):\n",
    "    if full:\n",
    "        exog=False\n",
    "        length = len(data)+1\n",
    "    else:\n",
    "        length = int(len(data)*percent)\n",
    "    if exog:\n",
    "        X,Xv= preprocess(init_data=data,exog=exog,facebook=facebook,logged=logged)\n",
    "\n",
    "        train, trainv = X.iloc[:length],Xv.iloc[:length]\n",
    "        test, testv = X.iloc[length:],Xv.iloc[length:]\n",
    "        return train,trainv,test,testv\n",
    "    else:\n",
    "        X = preprocess(init_data=data, exog=exog,facebook=facebook, logged=logged)\n",
    "\n",
    "        if full:\n",
    "            future_index = pd.date_range(start=X.index[-1], periods=60,freq='D')\n",
    "            if facebook:\n",
    "                future = pd.DataFrame(data=future_index,columns=['ds'])\n",
    "                train = X.iloc[:length]\n",
    "                test = future.copy()\n",
    "            else:\n",
    "                future = pd.DataFrame(data=future_index,columns=['Date'])\n",
    "                train = X.iloc[:length]\n",
    "                test = future.set_index('Date')\n",
    "        else:\n",
    "            train = X.iloc[:length]\n",
    "            test = X.iloc[length:]\n",
    "        return train, test\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base Model Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def base_model(data,exog=True, plotting=False, summary=False, mse=False, logged=False, full=False, roi=False):\n",
    "\n",
    "    # Failsafe just in case\n",
    "    if full:\n",
    "        exog=False\n",
    "        mse=False\n",
    "    else:\n",
    "        roi=False\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Get initial p,d,q from helper function\n",
    "    p,d,q = model_params(data=data, exog=exog, logged=logged)\n",
    "    \n",
    "    # Containers for train and test splits\n",
    "    trainpreds = pd.DataFrame()\n",
    "    testpreds = pd.DataFrame()\n",
    "    \n",
    "    # Splits the data, depending on modeling with/without exogenous, and models using SARIMAX model\n",
    "    if exog:\n",
    "        train,trainv,test,testv = train_test(data=data,exog=exog,logged=logged,full=full)\n",
    "        sarima = sm.tsa.SARIMAX(train,order=(p,d,q),trend='c',exog=trainv).fit()\n",
    "        trainpreds = sarima.predict()\n",
    "        forecast = sarima.get_forecast(len(test), index=test.index, exog=testv)\n",
    "        testpreds = forecast.predicted_mean\n",
    "        conf = forecast.conf_int(alpha=.05)\n",
    "    else:\n",
    "        train,test= train_test(data=data,exog=exog,logged=logged,full=full)\n",
    "        sarima = sm.tsa.SARIMAX(train,order=(p,d,q),trend='c').fit()      \n",
    "        trainpreds = sarima.predict()\n",
    "        forecast = sarima.get_forecast(len(test), index=test.index)\n",
    "        testpreds = forecast.predicted_mean\n",
    "        conf = forecast.conf_int(alpha=.05)\n",
    "        \n",
    "    \n",
    "    # Reverse transforms the data if log transformed initially\n",
    "    if logged:\n",
    "        itrain = np.exp(train)\n",
    "        itest = np.exp(test)\n",
    "        itrainpreds = np.exp(trainpreds)\n",
    "        itestpreds = np.exp(testpreds)\n",
    "        iconf = np.exp(conf)\n",
    "    else:\n",
    "        itrain = train.copy()\n",
    "        itest = test.copy()\n",
    "        itrainpreds = trainpreds.copy()\n",
    "        itestpreds = testpreds.copy()\n",
    "        iconf = conf.copy()\n",
    "        \n",
    "    # Plots the data and the forecasts\n",
    "    if plotting:\n",
    "        figure = plt.figure(figsize=(15,15))\n",
    "\n",
    "        plt.plot(itrain.append(itest), label='Original')\n",
    "        plt.plot(itrainpreds.append(itestpreds),label='Model')\n",
    "\n",
    "        conf_df = iconf.copy()\n",
    "        conf_df.columns =  ['y1','y2']\n",
    "        conf_df['X']=test.index\n",
    "        plt.fill_between(conf_df['X'],conf_df['y1'],conf_df['y2'], alpha=.2)        \n",
    "        \n",
    "        \n",
    "        \n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        \n",
    "        # Plots residual data\n",
    "        sarima.plot_diagnostics()\n",
    "    if summary:\n",
    "        print(sarima.summary())\n",
    "    if mse:\n",
    "#         print('Train RMSE: ', mean_squared_error(itrain, itrainpreds)**0.5)\n",
    "        print('Test RMSE: ', mean_squared_error(itest, itestpreds)**0.5)\n",
    "#         if aic:\n",
    "#             print('AIC: ', sarima.aic)\n",
    "\n",
    "    if roi:\n",
    "        start = itrainpreds[-1]\n",
    "        end = itestpreds[-1]\n",
    "        print(\"ROI: \", roi_calc(start=start,end=end),\"%\")\n",
    "    \n",
    "    return sarima "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auto Arima Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_auto_arima(data, exog=True, plotting=False, summary=False, mse=False, logged=False, full=False, roi = False):\n",
    "#     p,d,q = model_params(data,exog)\n",
    "    trainpreds = pd.DataFrame()\n",
    "    testpreds = pd.DataFrame()\n",
    "    \n",
    "    # Failsafe just in case\n",
    "    if full:\n",
    "        exog=False\n",
    "        mse=False\n",
    "    else:\n",
    "        roi = False\n",
    "    \n",
    "    if exog:\n",
    "        train,trainv,test,testv = train_test(data=data,exog=exog, logged=logged, full=full)\n",
    "        auto = auto_arima(y=train ,trace=True, exog=trainv,stepwise=True, max_order=12).fit(train)\n",
    "#         trainpreds = auto.predict()\n",
    "        testpreds, conf = auto.predict(len(test), index=test.index, exog=testv, return_conf_int=True)\n",
    "\n",
    "    else:\n",
    "        train,test= train_test(data=data,exog=exog, logged=logged, full=full)\n",
    "        auto = auto_arima(y=train ,trace=True,stepwise=True, max_order=12).fit(train)      \n",
    "        trainpreds = auto.predict()\n",
    "        testpreds, conf = auto.predict(len(test), index=test.index, return_conf_int=True)\n",
    "\n",
    "        \n",
    "        \n",
    "    if logged:\n",
    "        itrain = np.exp(train)\n",
    "        itest = np.exp(test)\n",
    "#         itrainpreds = np.exp(trainpreds)\n",
    "        itestpreds = np.exp(testpreds)\n",
    "        iconf = np.exp(conf)\n",
    "\n",
    "    else:\n",
    "        itrain = train.copy()\n",
    "        itest = test.copy()\n",
    "#         itrainpreds = trainpreds.copy()\n",
    "        itestpreds = testpreds.copy()\n",
    "#         print(testpreds)\n",
    "#         print(itestpreds)\n",
    "        iconf = conf.copy()\n",
    "        \n",
    "        \n",
    "    \n",
    "    if plotting:\n",
    "        plot_preds = pd.DataFrame(data=itestpreds, columns=['Adj Close'], index=itest.index)\n",
    "#         plot_preds['Date'] = test.index\n",
    "        \n",
    "        figure = plt.figure(figsize=(10,10))\n",
    "        \n",
    "        conf_df = pd.DataFrame(data=iconf, columns = ['y1','y2'])\n",
    "        conf_df['X']=test.index\n",
    "        plt.fill_between(conf_df['X'],conf_df['y1'],conf_df['y2'], alpha=.2)\n",
    "        \n",
    "        \n",
    "        plt.plot(itrain.append(itest), label='Original')\n",
    "        plt.plot(plot_preds,label='Model')\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        \n",
    "        auto.plot_diagnostics()\n",
    "    if summary:\n",
    "        print(auto.summary())\n",
    "    if mse:\n",
    "#         print('Train RMSE: ', mean_squared_error(train, trainpreds)**0.5)\n",
    "        print('Test RMSE: ', mean_squared_error(itest, itestpreds)**0.5)\n",
    "#         print(\"AIC:\",auto.aic())\n",
    "\n",
    "    if roi:\n",
    "        start = itestpreds[0]\n",
    "        end = itestpreds[-1]\n",
    "        print(\"ROI: \", roi_calc(start=start,end=end),\"%\")\n",
    "        \n",
    "    return auto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prophet Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prophet(data,exog=False,plotting=False,summary=False, mse=False, logged=False, full=False, roi=False):\n",
    "    fb, fbtest = train_test(data,exog=exog,facebook=True, logged=logged, full=full)\n",
    "    fb_model = Prophet(interval_width=.95, daily_seasonality=True)\n",
    "    fb_model.fit(fb)\n",
    "#     train = fb_model.predict(fb['ds'])\n",
    "    if full:\n",
    "        length = pd.date_range(start=fb.iloc[-1].ds, periods=60,freq='D')\n",
    "        mse = False\n",
    "    else:\n",
    "        length = pd.date_range(start=fb.iloc[0].ds, end=fbtest.iloc[-1].ds,freq='D')\n",
    "        roi = False\n",
    "    ifuture = pd.DataFrame(data=length,columns=['ds'])\n",
    "    iforecast = fb_model.predict(ifuture)\n",
    "\n",
    "    forecast = iforecast.copy()\n",
    "    \n",
    "#     if logged:\n",
    "#         forecast = iforecast.copy()\n",
    "#         for i in range(1,len(forecast.columns)):\n",
    "#             col = forecast.columns[i]\n",
    "#             forecast[col] = np.exp(iforecast[col])\n",
    "    \n",
    "    \n",
    "    if plotting:\n",
    "        fb_model.plot(forecast,uncertainty=True, figsize=(10,10));\n",
    "        plt.plot(fb.append(fbtest).set_index('ds'), c='red', label = 'Actual', alpha=.2)\n",
    "        plt.legend()\n",
    "\n",
    "    if mse:\n",
    "        train_error = pd.concat([forecast.set_index('ds'),fb.set_index('ds')], join='inner', axis=1)\n",
    "        test_error = pd.concat([forecast.set_index('ds'),fbtest.set_index('ds')], join='inner', axis=1)\n",
    "        \n",
    "#         print(\"Train RMSE:\", mean_squared_error(train_error.y,train_error.yhat)**.5)\n",
    "        print(\"Test RMSE:\", mean_squared_error(test_error.y,test_error.yhat)**.5)\n",
    "#         if aic:\n",
    "#             train_aic = len(train_error)*np.log(mean_squared_error(train_error.y,train_error.yhat)+2*1)\n",
    "#             print(\"AIC:\",train_aic)\n",
    "\n",
    "    if roi:\n",
    "        start = fb['y'].iloc[-1]\n",
    "        end = forecast['yhat'].iloc[-1]\n",
    "        print(\"ROI: \", roi_calc(start=start,end=end),\"%\")    \n",
    "\n",
    "    return fb_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Data/MongoDB.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10/19/2017</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>29.100000</td>\n",
       "      <td>32.07</td>\n",
       "      <td>32.07</td>\n",
       "      <td>11508500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10/20/2017</td>\n",
       "      <td>33.369999</td>\n",
       "      <td>33.369999</td>\n",
       "      <td>30.100000</td>\n",
       "      <td>30.68</td>\n",
       "      <td>30.68</td>\n",
       "      <td>2358700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10/23/2017</td>\n",
       "      <td>30.510000</td>\n",
       "      <td>31.330000</td>\n",
       "      <td>30.190001</td>\n",
       "      <td>30.50</td>\n",
       "      <td>30.50</td>\n",
       "      <td>749400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10/24/2017</td>\n",
       "      <td>30.459999</td>\n",
       "      <td>30.920000</td>\n",
       "      <td>30.438999</td>\n",
       "      <td>30.57</td>\n",
       "      <td>30.57</td>\n",
       "      <td>420700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10/25/2017</td>\n",
       "      <td>30.500000</td>\n",
       "      <td>31.100000</td>\n",
       "      <td>29.879999</td>\n",
       "      <td>31.00</td>\n",
       "      <td>31.00</td>\n",
       "      <td>1219400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date       Open       High        Low  Close  Adj Close    Volume\n",
       "0  10/19/2017  33.000000  34.000000  29.100000  32.07      32.07  11508500\n",
       "1  10/20/2017  33.369999  33.369999  30.100000  30.68      30.68   2358700\n",
       "2  10/23/2017  30.510000  31.330000  30.190001  30.50      30.50    749400\n",
       "3  10/24/2017  30.459999  30.920000  30.438999  30.57      30.57    420700\n",
       "4  10/25/2017  30.500000  31.100000  29.879999  31.00      31.00   1219400"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "455.1px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
